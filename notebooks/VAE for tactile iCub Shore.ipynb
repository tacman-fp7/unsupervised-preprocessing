{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tacman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt, cm\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from breze.learn.mlp import Mlp as learn_Mlp\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sensor = 'icub'\n",
    "datasetpath = '/home/<username>/Datasets/tacman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_shore = True\n",
    "if use_shore:\n",
    "    surface = tacman.datasets.shore.raw(path=datasetpath,sensor=sensor)\n",
    "else:\n",
    "    surface = tacman.datasets.surface.raw(path=datasetpath,sensor=sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split by experiments, not samples\n",
    "# not including experiment 0,66,68 and  one for iCub (extreme outlier)\n",
    "if os.path.isfile(sensor + '_' +('shore' if use_shore else 'surface') + '_ind.npy'):\n",
    "    ind = np.load(sensor + '_' +('shore' if use_shore else 'surface') + '_ind.npy')\n",
    "else:\n",
    "    ind = np.arange(0,len(surface.index.levels[0]))\n",
    "    ind = np.delete(ind, [0,66,68])\n",
    "    np.random.shuffle(ind)\n",
    "    np.save(sensor + '_' +('shore' if use_shore else 'surface') + '_ind.npy', ind)\n",
    "split = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_surface = surface.T[ind[0]].T\n",
    "for i in ind[1:int(split*len(ind))]:\n",
    "    train_surface = pd.concat([train_surface, surface.T[i].T])\n",
    "test_surface = surface.T[ind[int(split*len(ind))]].T\n",
    "for i in ind[int(split*len(ind))+1:]:\n",
    "    test_surface = pd.concat([test_surface, surface.T[i].T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_roll = (25.0/182.6 * 1.8)*13\n",
    "unit_pitch = 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(train_surface.T['E1':'E19' if sensor == 'biotac' else 'E12'].T)\n",
    "TX = np.array(test_surface.T['E1':'E19' if sensor == 'biotac' else 'E12'].T)\n",
    "\n",
    "X = scipy.ndimage.filters.gaussian_filter1d(X, 5, axis=0)\n",
    "TX = scipy.ndimage.filters.gaussian_filter1d(TX, 5, axis=0)\n",
    "\n",
    "Yp = np.array(train_surface['pitch'])\n",
    "TYp = np.array(test_surface['pitch'])\n",
    "\n",
    "Yr = np.array(train_surface['roll'])\n",
    "TYr = np.array(test_surface['roll'])\n",
    "\n",
    "if use_shore:\n",
    "    Ys = np.array(train_surface['shore'])\n",
    "    TYs = np.array(test_surface['shore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yr = Yr\n",
    "TYr = TYr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yp = Yp\n",
    "TYp = TYp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = X.mean(0)\n",
    "X -= mean\n",
    "std = X.std()\n",
    "X /= std\n",
    "TX -= mean\n",
    "TX /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(X[:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from breze.learn import sgvb\n",
    "import climin\n",
    "import climin.stops\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from breze.arch.construct.layer.distributions import DiagGauss, NormalGauss\n",
    "from breze.arch.construct.neural.distributions import MlpDiagGauss\n",
    "from breze.arch.construct.neural import Mlp\n",
    "\n",
    "class MlpDiagConstVarGauss(DiagGauss):\n",
    "    def __init__(self, inpt, n_inpt, n_hiddens, n_output,\n",
    "                 hidden_transfers, out_transfer_mean='identity',\n",
    "                 declare=None, name=None, rng=None):\n",
    "        self.inpt = inpt\n",
    "        self.n_inpt = n_inpt\n",
    "        self.n_hiddens = n_hiddens\n",
    "        self.n_output = n_output\n",
    "        self.hidden_transfers = hidden_transfers\n",
    "        self.out_transfer_mean = out_transfer_mean\n",
    "        self.mean_mlp = Mlp(\n",
    "            self.inpt, self.n_inpt, self.n_hiddens, self.n_output,\n",
    "            self.hidden_transfers,\n",
    "            self.out_transfer_mean,\n",
    "            declare=declare)\n",
    "        self.std = declare((1, n_output))\n",
    "        super(MlpDiagConstVarGauss, self).__init__(\n",
    "            self.mean_mlp.output,\n",
    "            self.std**2 + 1e-5)\n",
    "            \n",
    "            \n",
    "class MlpGaussConstVarVisibleVAEMixin(object):\n",
    "    def make_gen(self, latent_sample):\n",
    "        return MlpDiagConstVarGauss(\n",
    "            latent_sample, self.n_latent,\n",
    "            self.n_hiddens_gen,\n",
    "            self.n_inpt,\n",
    "            self.gen_transfers,\n",
    "            declare=self.parameters.declare)\n",
    "    \n",
    "class MlpGaussLatentVAEMixin(object):\n",
    "\n",
    "    def make_prior(self, sample):\n",
    "        return NormalGauss(sample.shape)\n",
    "\n",
    "    def make_recog(self, inpt):\n",
    "        return MlpDiagGauss(\n",
    "            inpt, self.n_inpt,\n",
    "            self.n_hiddens_recog,\n",
    "            self.n_latent,\n",
    "            self.recog_transfers,\n",
    "            out_transfer_mean='identity',\n",
    "            out_transfer_var= T.exp,\n",
    "            declare=self.parameters.declare)\n",
    "\n",
    "class MyVae(sgvb.VariationalAutoEncoder,\n",
    "                    MlpGaussLatentVAEMixin,\n",
    "                    MlpGaussConstVarVisibleVAEMixin):\n",
    "    pass\n",
    "\n",
    "optimizer = 'rmsprop', {'step_rate': 0.001}\n",
    "batch_size = 200\n",
    "\n",
    "n_latent = 128\n",
    "\n",
    "m = MyVae( int(X.shape[1]),\n",
    "                    [512] * 2, n_latent, [512] * 2,\n",
    "                    ['rectifier'] * 2, ['rectifier'] * 2,\n",
    "                    optimizer=optimizer, batch_size= batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "climin.initialize.randomize_normal(m.parameters.data, 0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(sensor + '_' +('shore' if use_shore else 'surface') + '_parameters.npy'):\n",
    "    m.parameters.data[:] = np.load(sensor + '_' +('shore' if use_shore else 'surface') + '_parameters.npy')\n",
    "else:\n",
    "    max_passes = 100\n",
    "    max_iter = max_passes * X.shape[0] / batch_size\n",
    "    n_report = X.shape[0] / batch_size\n",
    "\n",
    "    stop = climin.stops.AfterNIterations(max_iter)\n",
    "    pause = climin.stops.ModuloNIterations(n_report)\n",
    "\n",
    "    for i, info in enumerate(m.powerfit((X,), (TX,), stop, pause)):\n",
    "        print i, info['loss'], info['val_loss']\n",
    "\n",
    "    np.save(sensor + '_' +('shore' if use_shore else 'surface') + '_parameters.npy', m.parameters.data.as_numpy_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_f_latents = m.function(['inpt'], m.vae.recog.sample())\n",
    "f_latents = lambda x: _f_latents(x.astype('float32'))\n",
    "\n",
    "_f_mean = m.function(['inpt'], m.vae.recog.mean)\n",
    "f_mean = lambda x: _f_mean(x.astype('float32'))\n",
    "\n",
    "f_var = m.function(['inpt'], m.vae.recog.var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = f_latents(TX.astype('float32'))\n",
    "M = f_mean(TX.astype('float32'))\n",
    "V = f_var(TX.astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix: uniform latent vs. feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_latent_space(L,c):\n",
    "    n = L.shape[1]\n",
    "    fig, axs = plt.subplots(n, n, figsize=(10, 10))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                axs[i,j].hist2d(c, L[:,i], bins=(50,50))\n",
    "            elif i > j:\n",
    "                axs[i,j].scatter(L[:,i], L[:,j], c=c, marker='o')\n",
    "            else:\n",
    "                axs[i,j].set_axis_off()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L.shape, TYp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_linearregression(x,y,tx,ty):\n",
    "    m = linear_model.LinearRegression()\n",
    "    m.fit(x, y)\n",
    "    pred = m.predict(tx)\n",
    "    error = np.sqrt(((pred-ty)**2).mean())\n",
    "    return error, pred, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_dt(x,y,tx,ty):\n",
    "    import sklearn.tree\n",
    "    m = sklearn.tree.DecisionTreeRegressor(max_depth=5)\n",
    "    m.fit(x, y)\n",
    "    pred = m.predict(tx)\n",
    "    error = np.sqrt(((pred-ty)**2).mean())\n",
    "    return error, pred, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_mlp(x,y,tx,ty):\n",
    "    x = x.astype('float32')\n",
    "    y = y.astype('float32')\n",
    "    tx = tx.astype('float32')\n",
    "    ty = ty.astype('float32')\n",
    "    m = learn_Mlp(x.shape[1], [64, 64], 1, \n",
    "            hidden_transfers=['rectifier', 'rectifier'], out_transfer='identity',\n",
    "            loss=lambda x,y: (x-y)**2, \n",
    "            optimizer=optimizer, batch_size=batch_size, max_iter=max_iter)\n",
    "    \n",
    "    climin.initialize.randomize_normal(m.parameters.data, 0, 1e-2)\n",
    "    \n",
    "    stop = climin.stops.AfterNIterations(100)\n",
    "    report = climin.stops.ModuloNIterations(10)\n",
    "\n",
    "    for i, info in enumerate(m.powerfit((x.astype('float32'), y[:, np.newaxis].astype('float32')), (x[:1].astype('float32'), y[:, np.newaxis][:1].astype('float32')), stop, pause)):\n",
    "        pass\n",
    "    f_predict = m.function([m.inpt], m.output)\n",
    "    pred = f_predict(tx.astype('float32'))[:,0]\n",
    "    error = np.sqrt(((pred-ty)**2).mean())\n",
    "    return error, pred, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regression_targets = [\n",
    "            {'name': 'Force',\n",
    "             'Y':train_surface['force'], 'TY':test_surface['force'],\n",
    "            'visualY':train_surface['force'], 'visualTY':test_surface['force']},\n",
    "            \n",
    "            {'name': 'Pitch',\n",
    "             'Y':Yp, 'TY':TYp,\n",
    "             'visualY':Yp+np.random.uniform(size=Yp.shape)*unit_pitch-unit_pitch/2, 'visualTY':TYp+np.random.uniform(size=TYp.shape)*unit_pitch-unit_pitch/2},\n",
    "            \n",
    "            {'name': 'Roll',\n",
    "             'Y':Yr, 'TY':TYr,\n",
    "             'visualY':Yr+np.random.uniform(size=Yr.shape)*unit_roll-unit_roll/2, 'visualTY':TYr+np.random.uniform(size=TYr.shape)*unit_roll-unit_roll/2},\n",
    "    \n",
    "            {'name': 'Shore',\n",
    "             'Y':Ys, 'TY':TYs,\n",
    "             'visualY':Ys, 'visualTY':TYs},\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regression_algorithms = [\n",
    "    {'name': 'Linear Regression',\n",
    "     'fn': fit_linearregression\n",
    "    },\n",
    "    \n",
    "    {'name': 'Decision Tree Regression',\n",
    "     'fn': fit_dt\n",
    "    },\n",
    "    \n",
    "    #{'name': 'MLP',\n",
    "    # 'fn': fit_mlp\n",
    "    #}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano.config.compute_test_value = 'off'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fontsize = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for alg in regression_algorithms:\n",
    "    print '& \\\\multicolumn{2}{c}{' + alg['name'] + '} ',\n",
    "    \n",
    "print \"\\\\\\\\\\n\",\n",
    "    \n",
    "for alg in regression_algorithms:\n",
    "    print '& raw & latent',\n",
    "    \n",
    "print \"\\\\\\\\\\n\",\n",
    "\n",
    "for t in regression_targets:\n",
    "    print t['name'],\n",
    "    for alg in regression_algorithms:\n",
    "\n",
    "        print '&',\n",
    "        raw_error, raw_pred, raw_m = alg['fn'](X, t['Y'], TX, t['TY'])\n",
    "        print \"%.2f\" % raw_error,\n",
    "    \n",
    "        print '&',\n",
    "        latent_error, latent_pred, latent_m = alg['fn'](f_mean(X), t['Y'], f_mean(TX), t['TY'])\n",
    "        print \"%.2f\" % latent_error,\n",
    "        \n",
    "        # plot latent value with highest correlation to physical value\n",
    "        if alg['name'] == 'Linear Regression':\n",
    "            L = f_latents(np.concatenate( (X, TX), 0))\n",
    "            _m = linear_model.LinearRegression()\n",
    "            _m.fit(L, np.concatenate( (t['Y'],t['TY']), 0) )\n",
    "            indexes = np.argsort(-abs(_m.coef_))\n",
    "\n",
    "            for index in indexes[:1]:\n",
    "                fig, ax = plt.subplots(1,1, figsize=(4,4))\n",
    "                ax.set_ylabel(t['name'], fontsize=fontsize)\n",
    "                ax.set_xlabel('Latent variable #' + str(index) + ' [rel.]', fontsize=fontsize)\n",
    "\n",
    "                ax.hexbin(L[:,index], np.concatenate( (t['visualY'], t['visualTY']), 0))\n",
    "                ax.set_axis_bgcolor(plt.cm.jet(0))\n",
    "                ax.set_xlim([-4,4])\n",
    "                fig.savefig(t['name'] + '_latent_' + sensor + '.pdf')\n",
    "                \n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(2*4, 4))\n",
    "\n",
    "        ax[0].hexbin(raw_pred, t['visualTY'])\n",
    "        ax[0].set_xlim([np.min(t['visualTY']), np.max(t['visualTY'])])\n",
    "        ax[0].plot([np.min(t['visualTY']),np.max(t['visualTY'])], [np.min(t['visualTY']), np.max(t['visualTY'])], c='r')\n",
    "        ax[0].set_axis_bgcolor(plt.cm.jet(0))\n",
    "        ax[0].set_title('raw taxel\\nRMSE: ' + (\"%.2f\" % raw_error),  fontsize=fontsize)\n",
    "        ax[0].set_ylabel(t['name'],  fontsize=fontsize)\n",
    "        \n",
    "        ax[1].hexbin(latent_pred, t['visualTY'])\n",
    "        ax[1].set_xlim([np.min(t['visualTY']), np.max(t['visualTY'])])\n",
    "        ax[1].plot([np.min(t['visualTY']),np.max(t['visualTY'])], [np.min(t['visualTY']), np.max(t['visualTY'])], c='r')\n",
    "        ax[1].set_axis_bgcolor(plt.cm.jet(0))\n",
    "        ax[1].set_title('latent\\nRMSE: ' + (\"%.2f\" % latent_error),  fontsize=fontsize)\n",
    "        ax[1].set_ylabel(t['name'],  fontsize=fontsize)\n",
    "        fig.savefig(alg['name'].replace(' ', '') + '' + t['name'] + '_regression_' + sensor + '.pdf')\n",
    "    print '\\\\\\\\\\n',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
