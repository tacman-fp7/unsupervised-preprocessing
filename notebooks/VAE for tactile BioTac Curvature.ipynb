{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt, cm\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from breze.learn.mlp import Mlp\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tacman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sensor = 'biotac'\n",
    "datasetpath = '/home/<username>/Datasets/tacman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "surface = tacman.datasets.curvature.raw(path=datasetpath,sensor=sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split by experiments, not samples\n",
    "# not including experiment 0 one for iCub (extreme outlier)\n",
    "if os.path.isfile(sensor + '_curvature_ind.npy'):\n",
    "    ind = np.load(sensor + '_curvature_ind.npy')\n",
    "else:\n",
    "    ind = np.arange(len(surface))\n",
    "    np.random.shuffle(ind)\n",
    "    np.save(sensor + '_curvature_ind.npy', ind)\n",
    "split = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_surface = surface.iloc[ind[:int(split*len(ind))]]\n",
    "test_surface = surface.iloc[ind[int(split*len(ind)):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(train_surface.T['E1':'E19' if sensor == 'biotac' else 'E12'].T)\n",
    "TX = np.array(test_surface.T['E1':'E19' if sensor == 'biotac' else 'E12'].T)\n",
    "\n",
    "Y = np.array(train_surface['curvature'])\n",
    "TY = np.array(test_surface['curvature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = X.mean(0)\n",
    "X -= mean\n",
    "std = X.std(0)\n",
    "X /= std\n",
    "TX -= mean\n",
    "TX /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from breze.learn import sgvb\n",
    "import climin\n",
    "import climin.stops\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from breze.arch.construct.layer.distributions import DiagGauss, NormalGauss\n",
    "from breze.arch.construct.neural.distributions import MlpDiagGauss\n",
    "from breze.arch.construct.neural import Mlp\n",
    "\n",
    "class MlpDiagConstVarGauss(DiagGauss):\n",
    "    def __init__(self, inpt, n_inpt, n_hiddens, n_output,\n",
    "                 hidden_transfers, out_transfer_mean='identity',\n",
    "                 declare=None, name=None, rng=None):\n",
    "        self.inpt = inpt\n",
    "        self.n_inpt = n_inpt\n",
    "        self.n_hiddens = n_hiddens\n",
    "        self.n_output = n_output\n",
    "        self.hidden_transfers = hidden_transfers\n",
    "        self.out_transfer_mean = out_transfer_mean\n",
    "        self.mean_mlp = Mlp(\n",
    "            self.inpt, self.n_inpt, self.n_hiddens, self.n_output,\n",
    "            self.hidden_transfers,\n",
    "            self.out_transfer_mean,\n",
    "            declare=declare)\n",
    "        self.std = declare((1, n_output))\n",
    "        super(MlpDiagConstVarGauss, self).__init__(\n",
    "            self.mean_mlp.output,\n",
    "            self.std**2 + 1e-5)\n",
    "            \n",
    "            \n",
    "class MlpGaussConstVarVisibleVAEMixin(object):\n",
    "    def make_gen(self, latent_sample):\n",
    "        return MlpDiagConstVarGauss(\n",
    "            latent_sample, self.n_latent,\n",
    "            self.n_hiddens_gen,\n",
    "            self.n_inpt,\n",
    "            self.gen_transfers,\n",
    "            declare=self.parameters.declare)\n",
    "    \n",
    "class MlpGaussLatentVAEMixin(object):\n",
    "\n",
    "    def make_prior(self, sample):\n",
    "        return NormalGauss(sample.shape)\n",
    "\n",
    "    def make_recog(self, inpt):\n",
    "        return MlpDiagGauss(\n",
    "            inpt, self.n_inpt,\n",
    "            self.n_hiddens_recog,\n",
    "            self.n_latent,\n",
    "            self.recog_transfers,\n",
    "            out_transfer_mean='identity',\n",
    "            out_transfer_var= T.exp,\n",
    "            declare=self.parameters.declare)\n",
    "\n",
    "class MyVae(sgvb.VariationalAutoEncoder,\n",
    "                    MlpGaussLatentVAEMixin,\n",
    "                    MlpGaussConstVarVisibleVAEMixin):\n",
    "    pass\n",
    "\n",
    "optimizer = 'rmsprop', {'step_rate': 0.001}\n",
    "batch_size = 200\n",
    "\n",
    "n_latent = 128\n",
    "\n",
    "m = MyVae( int(X.shape[1]),\n",
    "                    [512] * 2, n_latent, [512] * 2,\n",
    "                    ['sigmoid'] * 2, ['sigmoid'] * 2,\n",
    "                    optimizer=optimizer, batch_size= batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "climin.initialize.randomize_normal(m.parameters.data, 0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(sensor + '_curvature_parameters.npy'):\n",
    "    m.parameters.data[:] = np.load(sensor + '_curvature_parameters.npy')\n",
    "else:\n",
    "    max_passes = 100\n",
    "    max_iter = max_passes * X.shape[0] / batch_size\n",
    "    n_report = X.shape[0] / batch_size\n",
    "\n",
    "    stop = climin.stops.AfterNIterations(max_iter)\n",
    "    pause = climin.stops.ModuloNIterations(n_report)\n",
    "\n",
    "    for i, info in enumerate(m.powerfit((X,), (X[0:1],), stop, pause)):\n",
    "        print i, info['loss'], info['val_loss']\n",
    "\n",
    "    np.save(sensor + '_curvature_parameters.npy', m.parameters.data.as_numpy_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from breze.learn.base import theanox\n",
    "_f_latents = m.function(['inpt'], m.vae.recog.sample())\n",
    "f_latents = lambda x: _f_latents(theanox(x)).as_numpy_array()\n",
    "\n",
    "_f_meanvar = m.function(['inpt'], m.vae.recog.stt)\n",
    "f_mean = lambda x: _f_meanvar(theanox(x)).as_numpy_array()[:, :n_latent]\n",
    "f_var = lambda x: _f_meanvar(theanox(x)).as_numpy_array()[:, n_latent:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = f_latents(theanox(TX))\n",
    "M = f_mean(theanox(TX))\n",
    "V = f_var(theanox(TX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix: uniform latent vs. feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_latent_space(L,c):\n",
    "    n = L.shape[1]\n",
    "    fig, axs = plt.subplots(n, n, figsize=(10, 10))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                axs[i,j].hist2d(c, L[:,i], bins=(50,50))\n",
    "            elif i > j:\n",
    "                axs[i,j].scatter(L[:,i], L[:,j], c=c, marker='o')\n",
    "            else:\n",
    "                axs[i,j].set_axis_off()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_latent_space(L[:,:5], TY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_logicsticregression(x,y,tx,ty):\n",
    "    from sklearn import preprocessing\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(map(str, y) + map(str, ty))\n",
    "\n",
    "    y = lb.transform(map(str, y))\n",
    "    ty = lb.transform(map(str, ty))\n",
    "    \n",
    "\n",
    "    m = linear_model.SGDClassifier(loss='log')\n",
    "    \n",
    "    m = linear_model.LinearRegression()\n",
    "    m.fit(x, y)\n",
    "    pred = m.predict(tx)\n",
    "    \n",
    "\n",
    "    import sklearn.metrics\n",
    "    error = sklearn.metrics.confusion_matrix(np.argmax(ty,1), np.argmax(pred,1))\n",
    "    return error, pred, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_algorithms = [\n",
    "    {'name': 'Logistic Regression',\n",
    "     'fn': fit_logicsticregression\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_targets = [\n",
    "    \n",
    "            {'name': 'Curvature',\n",
    "             'Y':Y, 'TY':TY},\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for alg in classification_algorithms:\n",
    "    print alg['name']\n",
    "    for t in classification_targets:\n",
    "\n",
    "        print t['name'], 'raw:',\n",
    "        raw_error, raw_pred, raw_m = alg['fn'](X, t['Y'], TX, t['TY'])\n",
    "        plt.figure()\n",
    "        plt.imshow(raw_error, interpolation=\"nearest\", cmap=plt.cm.binary)\n",
    "    \n",
    "        print 'latent:',\n",
    "        latent_error, latent_pred, latent_m = alg['fn'](f_mean(X), t['Y'], f_mean(TX), t['TY'])\n",
    "        plt.figure()\n",
    "        plt.imshow(latent_error, interpolation=\"nearest\", cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
